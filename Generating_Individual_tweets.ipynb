{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating_Individual_tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhijit-z/IDS_506_Omicron_Tweets_Analysis/blob/main/Generating_Individual_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retaining only those tweets that are most likely tweeted by individuals"
      ],
      "metadata": {
        "id": "2N5jNya5DYie"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3h4fURchmXI",
        "outputId": "5835ff05-aba8-45c3-898e-9ac799411f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from datetime import datetime\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = pd.read_csv(\"/content/drive/MyDrive/Omicron Tweet Analytics project/Filter2_res/Further_filtering/df_ff_11212021.csv\")\n",
        "print(file1.columns)\n",
        "\n",
        "file1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "tZytQcqGonAm",
        "outputId": "08b257aa-95ac-43f7-9d92-a15e17b00af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'coordinates', 'created_at', 'hashtags', 'place',\n",
            "       'source', 'user_id', 'user_description', 'user_name', 'id',\n",
            "       'user_screen_name', 'user_urls', 'user_verified', 'text', 'ind_org',\n",
            "       'name_plus_desp', 'name_plus_desp_clean', 'new_col2'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (9,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 coordinates                      created_at      hashtags place  \\\n",
              "0           0         NaN  Sun Nov 21 05:01:57 +0000 2021           NaN   NaN   \n",
              "1           1         NaN  Sun Nov 21 05:04:25 +0000 2021  chatwithmark   NaN   \n",
              "2           2         NaN  Sun Nov 21 05:03:38 +0000 2021           NaN   NaN   \n",
              "3           3         NaN  Sun Nov 21 05:02:24 +0000 2021           NaN   NaN   \n",
              "4           4         NaN  Sun Nov 21 05:03:34 +0000 2021           NaN   NaN   \n",
              "\n",
              "                                              source       user_id  \\\n",
              "0  <a href=\"http://publicize.wp.com/\" rel=\"nofoll...  3.064873e+09   \n",
              "1  <a href=\"http://twitter.com/download/android\" ...  1.272774e+18   \n",
              "2  <a href=\"http://twitter.com/download/android\" ...  1.448159e+18   \n",
              "3  <a href=\"http://twitter.com/download/android\" ...  1.345052e+18   \n",
              "4  <a href=\"https://mobile.twitter.com\" rel=\"nofo...  1.661808e+09   \n",
              "\n",
              "                                    user_description         user_name  \\\n",
              "0  Breaking news, sport, TV, radio and a whole lo...   BalkansTimes.eu   \n",
              "1  #Got7:JB|M|J|JY|YJ|Y|BB|YG| ìÖ© |\\nseven or neve...             jelly   \n",
              "2                                                NaN  SilverSamurai714   \n",
              "3                                       DvidThomsonB        DavidBxxxx   \n",
              "4  I want action on climate change. Follows IA no...        whatismore   \n",
              "\n",
              "                    id user_screen_name                     user_urls  \\\n",
              "0  1462285128420544514   BalkansTimesEu  https://www.balkanstimes.eu/   \n",
              "1  1462285749101875202          getdab7                           NaN   \n",
              "2  1462285552988786695  SilverSamurai85                           NaN   \n",
              "3  1462285241763069957    ThomsonBreage                           NaN   \n",
              "4  1462285537075556357  SandraC81413369                           NaN   \n",
              "\n",
              "  user_verified                                               text ind_org  \\\n",
              "0         False  Ottawa under fire for changes to COVID-19 bord...     ind   \n",
              "1         False  @marktuan #chatwithmark \\n\\nget i get a hug fr...     ind   \n",
              "2         False  @Faceplants00 @RWMaloneMD Why? The testing is ...     ind   \n",
              "3         False  She is Miss BJP 2021 Covid19 edition. https://...     ind   \n",
              "4         False  @sublimespirit @HelenErrington1 What choice do...     ind   \n",
              "\n",
              "                                      name_plus_desp  \\\n",
              "0  BalkansTimes.eu Breaking news, sport, TV, radi...   \n",
              "1  jelly #Got7:JB|M|J|JY|YJ|Y|BB|YG| ìÖ© |\\nseven o...   \n",
              "2                                                NaN   \n",
              "3                            DavidBxxxx DvidThomsonB   \n",
              "4  whatismore I want action on climate change. Fo...   \n",
              "\n",
              "                                name_plus_desp_clean new_col2  \n",
              "0  balkanstimeseu breaking news sport tv radio wh...      org  \n",
              "1  jelly got7jbmjjyyjybbyg seven never everever g...      ind  \n",
              "2                                                NaN      ind  \n",
              "3                            davidbxxxx dvidthomsonb      ind  \n",
              "4  whatismore action climate change follows abc l...      ind  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70529c9d-eac2-472e-81e0-c10339134132\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>created_at</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>place</th>\n",
              "      <th>source</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_name</th>\n",
              "      <th>id</th>\n",
              "      <th>user_screen_name</th>\n",
              "      <th>user_urls</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>text</th>\n",
              "      <th>ind_org</th>\n",
              "      <th>name_plus_desp</th>\n",
              "      <th>name_plus_desp_clean</th>\n",
              "      <th>new_col2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 21 05:01:57 +0000 2021</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://publicize.wp.com/\" rel=\"nofoll...</td>\n",
              "      <td>3.064873e+09</td>\n",
              "      <td>Breaking news, sport, TV, radio and a whole lo...</td>\n",
              "      <td>BalkansTimes.eu</td>\n",
              "      <td>1462285128420544514</td>\n",
              "      <td>BalkansTimesEu</td>\n",
              "      <td>https://www.balkanstimes.eu/</td>\n",
              "      <td>False</td>\n",
              "      <td>Ottawa under fire for changes to COVID-19 bord...</td>\n",
              "      <td>ind</td>\n",
              "      <td>BalkansTimes.eu Breaking news, sport, TV, radi...</td>\n",
              "      <td>balkanstimeseu breaking news sport tv radio wh...</td>\n",
              "      <td>org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 21 05:04:25 +0000 2021</td>\n",
              "      <td>chatwithmark</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>1.272774e+18</td>\n",
              "      <td>#Got7:JB|M|J|JY|YJ|Y|BB|YG| ìÖ© |\\nseven or neve...</td>\n",
              "      <td>jelly</td>\n",
              "      <td>1462285749101875202</td>\n",
              "      <td>getdab7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>@marktuan #chatwithmark \\n\\nget i get a hug fr...</td>\n",
              "      <td>ind</td>\n",
              "      <td>jelly #Got7:JB|M|J|JY|YJ|Y|BB|YG| ìÖ© |\\nseven o...</td>\n",
              "      <td>jelly got7jbmjjyyjybbyg seven never everever g...</td>\n",
              "      <td>ind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 21 05:03:38 +0000 2021</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>1.448159e+18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SilverSamurai714</td>\n",
              "      <td>1462285552988786695</td>\n",
              "      <td>SilverSamurai85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>@Faceplants00 @RWMaloneMD Why? The testing is ...</td>\n",
              "      <td>ind</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 21 05:02:24 +0000 2021</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>1.345052e+18</td>\n",
              "      <td>DvidThomsonB</td>\n",
              "      <td>DavidBxxxx</td>\n",
              "      <td>1462285241763069957</td>\n",
              "      <td>ThomsonBreage</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>She is Miss BJP 2021 Covid19 edition. https://...</td>\n",
              "      <td>ind</td>\n",
              "      <td>DavidBxxxx DvidThomsonB</td>\n",
              "      <td>davidbxxxx dvidthomsonb</td>\n",
              "      <td>ind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sun Nov 21 05:03:34 +0000 2021</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>1.661808e+09</td>\n",
              "      <td>I want action on climate change. Follows IA no...</td>\n",
              "      <td>whatismore</td>\n",
              "      <td>1462285537075556357</td>\n",
              "      <td>SandraC81413369</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>@sublimespirit @HelenErrington1 What choice do...</td>\n",
              "      <td>ind</td>\n",
              "      <td>whatismore I want action on climate change. Fo...</td>\n",
              "      <td>whatismore action climate change follows abc l...</td>\n",
              "      <td>ind</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70529c9d-eac2-472e-81e0-c10339134132')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70529c9d-eac2-472e-81e0-c10339134132 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70529c9d-eac2-472e-81e0-c10339134132');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#file1['id'] = file1['id'].astype(float)\n",
        "#file1[file1['id'] == 'agsb_bilbao']"
      ],
      "metadata": {
        "id": "RMrd_RWMjHNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#file1.dtypes"
      ],
      "metadata": {
        "id": "pepCLA0wi9r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#file1[file1[[ 'id', 'text']]['new_col2']=='org']\n",
        "#new_df = file1[file1['new_col2']=='org'][['id', 'text']]\n",
        "#new_df"
      ],
      "metadata": {
        "id": "RZLBGT3Js2Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "date1 = '2021-11-21'\n",
        "date2 = '2021-11-21'\n",
        "#date2 = '2022-01-31'\n",
        "\n",
        "mydates = pd.date_range(date1, date2, freq='d')#.tolist()\n",
        "mydates\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iwZ9Y1Xyhp-K",
        "outputId": "4080291c-052c-42be-c837-acf3758b629e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndate1 = '2021-11-21'\\ndate2 = '2021-11-21'\\n#date2 = '2022-01-31'\\n\\nmydates = pd.date_range(date1, date2, freq='d')#.tolist()\\nmydates\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date1 = '2021-11-21'\n",
        "date2 = '2022-01-31'\n",
        "\n",
        "mydates = pd.date_range(date1, date2, freq='d')#.tolist()\n",
        "print(mydates)\n",
        "for d in pd.date_range(date1, date2, freq='d'):\n",
        "  d_str = d.strftime(\"%m%d%Y\")\n",
        "  print(d_str)\n",
        "\n",
        "  path = \"/content/drive/MyDrive/Omicron Tweet Analytics project/Filter2_res/Further_filtering/df_ff_\" + d_str + \".csv\"\n",
        "  df = pd.read_csv(path, engine= 'python')\n",
        "  df_reduced = df[df['new_col2']=='ind'][['user_id','created_at','id', 'text']]\n",
        "\n",
        "  path2 = \"/content/drive/MyDrive/Omicron Tweet Analytics project/Filter3_res/Only_ind_tweets\"\n",
        "\n",
        "  isExist = os.path.exists(path2)\n",
        "  if not isExist:\n",
        "  \n",
        "    # Create a new directory because it does not exist \n",
        "    os.makedirs(path2)\n",
        "    print(\"The new directory is created!\")\n",
        "  dest_path = \"/content/drive/MyDrive/Omicron Tweet Analytics project/Filter3_res/Only_ind_tweets/df_ind_tweets_\" + d_str + \".csv\"\n",
        "  df_reduced.to_csv(dest_path)"
      ],
      "metadata": {
        "id": "tmqf1pEs6Dvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e227a12b-96ff-4690-c41f-13475f3a3f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndex(['2021-11-21', '2021-11-22', '2021-11-23', '2021-11-24',\n",
            "               '2021-11-25', '2021-11-26', '2021-11-27', '2021-11-28',\n",
            "               '2021-11-29', '2021-11-30', '2021-12-01', '2021-12-02',\n",
            "               '2021-12-03', '2021-12-04', '2021-12-05', '2021-12-06',\n",
            "               '2021-12-07', '2021-12-08', '2021-12-09', '2021-12-10',\n",
            "               '2021-12-11', '2021-12-12', '2021-12-13', '2021-12-14',\n",
            "               '2021-12-15', '2021-12-16', '2021-12-17', '2021-12-18',\n",
            "               '2021-12-19', '2021-12-20', '2021-12-21', '2021-12-22',\n",
            "               '2021-12-23', '2021-12-24', '2021-12-25', '2021-12-26',\n",
            "               '2021-12-27', '2021-12-28', '2021-12-29', '2021-12-30',\n",
            "               '2021-12-31', '2022-01-01', '2022-01-02', '2022-01-03',\n",
            "               '2022-01-04', '2022-01-05', '2022-01-06', '2022-01-07',\n",
            "               '2022-01-08', '2022-01-09', '2022-01-10', '2022-01-11',\n",
            "               '2022-01-12', '2022-01-13', '2022-01-14', '2022-01-15',\n",
            "               '2022-01-16', '2022-01-17', '2022-01-18', '2022-01-19',\n",
            "               '2022-01-20', '2022-01-21', '2022-01-22', '2022-01-23',\n",
            "               '2022-01-24', '2022-01-25', '2022-01-26', '2022-01-27',\n",
            "               '2022-01-28', '2022-01-29', '2022-01-30', '2022-01-31'],\n",
            "              dtype='datetime64[ns]', freq='D')\n",
            "11212021\n",
            "The new directory is created!\n",
            "11222021\n",
            "11232021\n",
            "11242021\n",
            "11252021\n",
            "11262021\n",
            "11272021\n",
            "11282021\n",
            "11292021\n",
            "11302021\n",
            "12012021\n",
            "12022021\n",
            "12032021\n",
            "12042021\n",
            "12052021\n",
            "12062021\n",
            "12072021\n",
            "12082021\n",
            "12092021\n",
            "12102021\n",
            "12112021\n",
            "12122021\n",
            "12132021\n",
            "12142021\n",
            "12152021\n",
            "12162021\n",
            "12172021\n",
            "12182021\n",
            "12192021\n",
            "12202021\n",
            "12212021\n",
            "12222021\n",
            "12232021\n",
            "12242021\n",
            "12252021\n",
            "12262021\n",
            "12272021\n",
            "12282021\n",
            "12292021\n",
            "12302021\n",
            "12312021\n",
            "01012022\n",
            "01022022\n",
            "01032022\n",
            "01042022\n",
            "01052022\n",
            "01062022\n",
            "01072022\n",
            "01082022\n",
            "01092022\n",
            "01102022\n",
            "01112022\n",
            "01122022\n",
            "01132022\n",
            "01142022\n",
            "01152022\n",
            "01162022\n",
            "01172022\n",
            "01182022\n",
            "01192022\n",
            "01202022\n",
            "01212022\n",
            "01222022\n",
            "01232022\n",
            "01242022\n",
            "01252022\n",
            "01262022\n",
            "01272022\n",
            "01282022\n",
            "01292022\n",
            "01302022\n",
            "01312022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y_5cZmI9LpLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "p = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Only_ind_tweets/df_ind_tweets_11262021.csv\"\n",
        "df_p = pd.read_csv(p, engine='python')\n",
        "df_p.columns\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3dpMJPfyNIE4",
        "outputId": "a581b3a5-1873-4ec3-986c-e063c982f50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\np = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Only_ind_tweets/df_ind_tweets_11262021.csv\"\\ndf_p = pd.read_csv(p, engine=\\'python\\')\\ndf_p.columns\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "date1 = '2021-11-23'\n",
        "date2 = '2022-01-31'\n",
        "\n",
        "mydates = pd.date_range(date1, date2, freq='d')#.tolist()\n",
        "print(mydates)\n",
        "for d in pd.date_range(date1, date2, freq='d'):\n",
        "  d_str = d.strftime(\"%m%d%Y\")\n",
        "  print(d_str)\n",
        "  path = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Further Filtered/df_ff_\" + d_str + \".csv\"\n",
        "\n",
        "  df = pd.read_csv(path, engine= 'python')\n",
        "  df_reduced = df[df['new_col2']=='ind'][['id', 'text']]\n",
        "\n",
        "  path2 = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Only_ind_tweets\"\n",
        "\n",
        "  #os.makedirs(path, exist_ok=False)\n",
        "  isExist = os.path.exists(path2)\n",
        "  if not isExist:\n",
        "  \n",
        "    # Create a new directory because it does not exist \n",
        "    os.makedirs(path2)\n",
        "    print(\"The new directory is created!\")\n",
        "  dest_path = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Only_ind_tweets/df_ind_tweets_\" + d_str + \".csv\"\n",
        "  df_reduced.to_csv(dest_path)\n",
        "\n",
        "  '''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "1ksrnYQwu0PT",
        "outputId": "50deb459-dfb7-45f4-eed1-923a4154596d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndate1 = \\'2021-11-23\\'\\ndate2 = \\'2022-01-31\\'\\n\\nmydates = pd.date_range(date1, date2, freq=\\'d\\')#.tolist()\\nprint(mydates)\\nfor d in pd.date_range(date1, date2, freq=\\'d\\'):\\n  d_str = d.strftime(\"%m%d%Y\")\\n  print(d_str)\\n  path = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Further Filtered/df_ff_\" + d_str + \".csv\"\\n\\n  df = pd.read_csv(path, engine= \\'python\\')\\n  df_reduced = df[df[\\'new_col2\\']==\\'ind\\'][[\\'id\\', \\'text\\']]\\n\\n  path2 = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Only_ind_tweets\"\\n\\n  #os.makedirs(path, exist_ok=False)\\n  isExist = os.path.exists(path2)\\n  if not isExist:\\n  \\n    # Create a new directory because it does not exist \\n    os.makedirs(path2)\\n    print(\"The new directory is created!\")\\n  dest_path = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Only_ind_tweets/df_ind_tweets_\" + d_str + \".csv\"\\n  df_reduced.to_csv(dest_path)\\n\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "date1 = '2021-11-21'\n",
        "date2 = '2021-11-30'\n",
        "\n",
        "#date1 = datetime.datetime.strptime('12012021', '%m%d%Y')\n",
        "#date2 = datetime.datetime.strptime('12022021', '%m%d%Y')\n",
        "\n",
        "mydates = pd.date_range(date1, date2, freq='d')#.tolist()\n",
        "print(mydates)\n",
        "for d in pd.date_range(date1, date2, freq='d'):\n",
        "  d_str = d.strftime(\"%m%d%Y\")\n",
        "  print(d_str)\n",
        "  path = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Further Filtered/df_ff_\" + d_str + \".csv\"\n",
        "\n",
        "  df = pd.read_csv(path, engine= 'python')\n",
        "  df_reduced = df[df['new_col2']=='ind'][['id', 'text']]\n",
        "\n",
        "  nltk.download('punkt')\n",
        "  nltk.download('stopwords')\n",
        "\n",
        "  STOP_WORDS = stopwords.words()\n",
        "\n",
        "  # removing the emojies\n",
        "  # https://www.kaggle.com/alankritamishra/covid-19-tweet-sentiment-analysis#Sentiment-analysis\n",
        "  EMOJI_PATTERN = re.compile(\"[\"\n",
        "                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                            u\"\\U00002702-\\U000027B0\"\n",
        "                            u\"\\U000024C2-\\U0001F251\"\n",
        "                            \"]+\", flags=re.UNICODE)\n",
        "\n",
        "\n",
        "  def cleaning(text):\n",
        "      \"\"\"\n",
        "      Convert to lowercase.\n",
        "      Rremove URL links, special characters and punctuation.\n",
        "      Tokenize and remove stop words.\n",
        "      \"\"\"\n",
        "      text = text.lower()\n",
        "      text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "      text = re.sub('@[A-Za-z0-9]+', '', text)\n",
        "      text = re.sub('<.*?>+', '', text)   # replacing HTML text with blank or whitespace\n",
        "      text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "      text = re.sub('\\n', '', text)\n",
        "      text = re.sub('[‚Äô‚Äú‚Äù‚Ä¶]', '', text)\n",
        "      \n",
        "      text = text.encode(\"ascii\", \"ignore\")     # consider only english alphanumeric characters\n",
        "      text = text.decode()\n",
        "      \n",
        "      text = EMOJI_PATTERN.sub(r'', text)\n",
        "    \n",
        "      \n",
        "      \n",
        "      # removing the stop-words\n",
        "      text_tokens = word_tokenize(text)\n",
        "      tokens_without_sw = [\n",
        "        word for word in text_tokens if not word in STOP_WORDS]\n",
        "      filtered_sentence = (\" \").join(tokens_without_sw)\n",
        "      text = filtered_sentence\n",
        "      \n",
        "      return text\n",
        "\n",
        "  def func2(val1, val2):\n",
        "    for word in uniq_list:\n",
        "        if (word in val1):     # may use val2 ie user_verified status for additional filtering\n",
        "            return \"org\"\n",
        "        else:\n",
        "            return \"ind\"\n",
        "\n",
        "  #if __name__ == \"__main__\":\n",
        "  #    max_rows = 1000  # 'None' to read whole file\n",
        "      \n",
        "  #df = pd.read_csv(\"Labeled_tweets.csv\")\n",
        "  #df.head()\n",
        "  df_reduced['name_plus_desp'] = df_reduced['user_name'] + \" \" + df_reduced['user_description']\n",
        "  df_reduced['name_plus_desp'] = df_reduced['name_plus_desp'].astype(str)\n",
        "  df_reduced.head() \n",
        "  \n",
        "  #dt = df_reduced['name_plus_desp'].apply(cleaning)\n",
        "  df_reduced['name_plus_desp_clean'] = df_reduced['name_plus_desp'].apply(cleaning)\n",
        "  \n",
        "  #print(df_reduced['name_plus_desp_clean'])\n",
        "  print(\"\\n\")\n",
        "  \n",
        "  # word_count = Counter(\" \".join(dt).split()).most_common(10)\n",
        "  # word_frequency = pd.DataFrame(word_count, columns = ['Word', 'Frequency'])\n",
        "  # print(word_frequency)\n",
        "  \n",
        "  df_reduced['new_col2'] = df_reduced.apply(lambda row: func2(row['name_plus_desp_clean'], row['user_verified']), axis =1)\n",
        "  print(df_reduced['new_col2'].value_counts())\n",
        "  \n",
        "  path2 = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Further_filtering\"\n",
        "\n",
        "  #os.makedirs(path, exist_ok=False)\n",
        "  isExist = os.path.exists(path2)\n",
        "  if not isExist:\n",
        "  \n",
        "    # Create a new directory because it does not exist \n",
        "    os.makedirs(path2)\n",
        "    print(\"The new directory is created!\")\n",
        "  dest_path = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Further_filtering/df_ff_\" + d_str + \".csv\"\n",
        "  df_reduced.to_csv(dest_path)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "quTQNnA4h7RS",
        "outputId": "a2578cd1-a3fe-4b6b-eb30-2ddaa565ec1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndate1 = \\'2021-11-21\\'\\ndate2 = \\'2021-11-30\\'\\n\\n#date1 = datetime.datetime.strptime(\\'12012021\\', \\'%m%d%Y\\')\\n#date2 = datetime.datetime.strptime(\\'12022021\\', \\'%m%d%Y\\')\\n\\nmydates = pd.date_range(date1, date2, freq=\\'d\\')#.tolist()\\nprint(mydates)\\nfor d in pd.date_range(date1, date2, freq=\\'d\\'):\\n  d_str = d.strftime(\"%m%d%Y\")\\n  print(d_str)\\n  path = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Further Filtered/df_ff_\" + d_str + \".csv\"\\n\\n  df = pd.read_csv(path, engine= \\'python\\')\\n  df_reduced = df[df[\\'new_col2\\']==\\'ind\\'][[\\'id\\', \\'text\\']]\\n\\n  nltk.download(\\'punkt\\')\\n  nltk.download(\\'stopwords\\')\\n\\n  STOP_WORDS = stopwords.words()\\n\\n  # removing the emojies\\n  # https://www.kaggle.com/alankritamishra/covid-19-tweet-sentiment-analysis#Sentiment-analysis\\n  EMOJI_PATTERN = re.compile(\"[\"\\n                            u\"üòÄ-üôè\"  # emoticons\\n                            u\"üåÄ-üóø\"  # symbols & pictographs\\n                            u\"üöÄ-\\U0001f6ff\"  # transport & map symbols\\n                            u\"\\U0001f1e0-üáø\"  # flags (iOS)\\n                            u\"‚úÇ-‚û∞\"\\n                            u\"‚ìÇ-üâë\"\\n                            \"]+\", flags=re.UNICODE)\\n\\n\\n  def cleaning(text):\\n      \"\"\"\\n      Convert to lowercase.\\n      Rremove URL links, special characters and punctuation.\\n      Tokenize and remove stop words.\\n      \"\"\"\\n      text = text.lower()\\n      text = re.sub(\\'https?://\\\\S+|www\\\\.\\\\S+\\', \\'\\', text)\\n      text = re.sub(\\'@[A-Za-z0-9]+\\', \\'\\', text)\\n      text = re.sub(\\'<.*?>+\\', \\'\\', text)   # replacing HTML text with blank or whitespace\\n      text = re.sub(\\'[%s]\\' % re.escape(string.punctuation), \\'\\', text)\\n      text = re.sub(\\'\\n\\', \\'\\', text)\\n      text = re.sub(\\'[‚Äô‚Äú‚Äù‚Ä¶]\\', \\'\\', text)\\n      \\n      text = text.encode(\"ascii\", \"ignore\")     # consider only english alphanumeric characters\\n      text = text.decode()\\n      \\n      text = EMOJI_PATTERN.sub(r\\'\\', text)\\n    \\n      \\n      \\n      # removing the stop-words\\n      text_tokens = word_tokenize(text)\\n      tokens_without_sw = [\\n        word for word in text_tokens if not word in STOP_WORDS]\\n      filtered_sentence = (\" \").join(tokens_without_sw)\\n      text = filtered_sentence\\n      \\n      return text\\n\\n  def func2(val1, val2):\\n    for word in uniq_list:\\n        if (word in val1):     # may use val2 ie user_verified status for additional filtering\\n            return \"org\"\\n        else:\\n            return \"ind\"\\n\\n  #if __name__ == \"__main__\":\\n  #    max_rows = 1000  # \\'None\\' to read whole file\\n      \\n  #df = pd.read_csv(\"Labeled_tweets.csv\")\\n  #df.head()\\n  df_reduced[\\'name_plus_desp\\'] = df_reduced[\\'user_name\\'] + \" \" + df_reduced[\\'user_description\\']\\n  df_reduced[\\'name_plus_desp\\'] = df_reduced[\\'name_plus_desp\\'].astype(str)\\n  df_reduced.head() \\n  \\n  #dt = df_reduced[\\'name_plus_desp\\'].apply(cleaning)\\n  df_reduced[\\'name_plus_desp_clean\\'] = df_reduced[\\'name_plus_desp\\'].apply(cleaning)\\n  \\n  #print(df_reduced[\\'name_plus_desp_clean\\'])\\n  print(\"\\n\")\\n  \\n  # word_count = Counter(\" \".join(dt).split()).most_common(10)\\n  # word_frequency = pd.DataFrame(word_count, columns = [\\'Word\\', \\'Frequency\\'])\\n  # print(word_frequency)\\n  \\n  df_reduced[\\'new_col2\\'] = df_reduced.apply(lambda row: func2(row[\\'name_plus_desp_clean\\'], row[\\'user_verified\\']), axis =1)\\n  print(df_reduced[\\'new_col2\\'].value_counts())\\n  \\n  path2 = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Further_filtering\"\\n\\n  #os.makedirs(path, exist_ok=False)\\n  isExist = os.path.exists(path2)\\n  if not isExist:\\n  \\n    # Create a new directory because it does not exist \\n    os.makedirs(path2)\\n    print(\"The new directory is created!\")\\n  dest_path = \"/content/drive/MyDrive/IDS 506 Healthcare Analytics/506 Project/Further_filtering/df_ff_\" + d_str + \".csv\"\\n  df_reduced.to_csv(dest_path)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "\n",
        "def func2(val1, val2):\n",
        "    for word in uniq_list:\n",
        "        if (word in val1):     # may use val2 ie user_verified status for additional filtering\n",
        "            return \"org\"\n",
        "        else:\n",
        "            return \"ind\"\n",
        "\n",
        "df_reduced['new_col2'] = df_reduced.apply(lambda row: func2(row['name_plus_desp_clean'], row['user_verified']), axis =1)\n",
        "'''"
      ],
      "metadata": {
        "id": "xS63Vb1Xh7Nx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ad52d3f6-f723-497a-b8e7-5e443072df90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\ndef func2(val1, val2):\\n    for word in uniq_list:\\n        if (word in val1):     # may use val2 ie user_verified status for additional filtering\\n            return \"org\"\\n        else:\\n            return \"ind\"\\n\\ndf_reduced[\\'new_col2\\'] = df_reduced.apply(lambda row: func2(row[\\'name_plus_desp_clean\\'], row[\\'user_verified\\']), axis =1)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ME6Zbvosh7LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yhJ_8R8Lh7Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0pEBCrNoh7F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8czqHxaqh7DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PYR8B17ch7A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kjLPg4qnh6-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1PR0TgE3h67Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}